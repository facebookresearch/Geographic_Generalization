# @package _global_
defaults:
  - override /hydra/launcher: submitit_slurm

project: mise-en-place

trainer:
  gpus: 1
  num_nodes: 1
  strategy: null
  max_epochs: 100

partitions:
  dianeb: learnlab,devlab
  marksibrahim: learnlab,devlab
  # H1 only has learnfair, not learnlab

hydra:
  launcher:
    gpus_per_node: ${trainer.gpus}
    tasks_per_node: ${trainer.gpus}
    cpus_per_task: 8
    mem_gb: 80
    nodes: ${trainer.num_nodes}
    timeout_min: 1000
    max_num_timeout: 5
    partition: ${partitions[${oc.env:USER}]}
    comment: mise-en-place
    # only 32gb GPUs with good networking
    # based on https://github.com/fairinternal/fairscale_benchmarks/commit/2b4ed0f8c49bdd182cdc02baa955487a65dd079c
    constraint: volta32gb,ib4